name: Python Tests

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11]
      fail-fast: false  # Continue running other matrix jobs if one fails

    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0  # Fetch all history for better coverage reporting
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8 mypy black pytest-html
    
    - name: Lint with flake8
      run: |
        # stop the build if there are Python syntax errors or undefined names
        flake8 imagen_desktop --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings
        flake8 imagen_desktop --count --exit-zero --max-complexity=10 --max-line-length=100 --statistics
    
    - name: Check formatting with black
      run: |
        black --check imagen_desktop
      # Now we enforce proper formatting
    
    - name: Type check with mypy
      run: |
        mypy imagen_desktop
      # Now we enforce type checking
    
    - name: Test with pytest
      run: |
        python -m pytest -m "not ui" --cov=imagen_desktop --cov-config=.coveragerc --cov-report=xml --cov-report=html --cov-report=json --html=pytest-report.html --self-contained-html
    
    - name: Upload coverage reports to Codecov
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage.xml
        fail_ci_if_error: true
        flags: unittests
        name: codecov-umbrella
        verbose: true
        
    - name: Upload test reports
      uses: actions/upload-artifact@v3
      if: always()  # Upload even if tests fail
      with:
        name: test-reports-${{ matrix.python-version }}
        path: |
          pytest-report.html
          htmlcov/
          coverage.json
          coverage.xml
          
    - name: Generate coverage badge
      run: |
        pip install genbadge[coverage]
        genbadge coverage -i coverage.xml -o coverage-badge.svg
        
    - name: Generate detailed coverage report
      run: |
        # Create detailed module coverage report
        mkdir -p coverage-report
        python -c "
        import json
        import os
        from datetime import datetime
        
        # Load JSON report for detailed coverage
        with open('coverage.json') as f:
            cov_data = json.load(f)
            
        # Get config from .coveragerc
        import configparser
        config = configparser.ConfigParser()
        config.read('.coveragerc')
        min_total = float(config['coverage:report']['fail_under'])
        
        # Calculate total coverage
        total_coverage = cov_data['totals']['percent_covered']
        
        # Create markdown report
        with open('coverage-report/coverage.md', 'w') as report:
            report.write('# Code Coverage Report\n\n')
            report.write(f'Generated on: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n\n')
            report.write(f'**Total coverage: {total_coverage:.2f}%** (Minimum required: {min_total}%)\n\n')
            
            # Add badge reference
            report.write('![Coverage Badge](../coverage-badge.svg)\n\n')
            
            # Add module-level table
            report.write('## Module Coverage\n\n')
            report.write('| Module | Coverage | Status |\n')
            report.write('|--------|----------|--------|\n')
            
            # Get module data
            module_data = []
            for file_path, metrics in cov_data['files'].items():
                if '/tests/' not in file_path:  # Skip test files
                    module_name = file_path.replace('imagen_desktop/', '')
                    cov_percent = metrics['summary']['percent_covered']
                    status = '✅' if cov_percent >= min_total else '❌'
                    module_data.append((module_name, cov_percent, status))
            
            # Sort by coverage (ascending)
            module_data.sort(key=lambda x: x[1])
            
            # Write module data
            for module, coverage, status in module_data:
                report.write(f'| {module} | {coverage:.2f}% | {status} |\n')
        
        # Create badge file backup in coverage-report dir
        import shutil
        shutil.copy('coverage-badge.svg', 'coverage-report/coverage-badge.svg')
        "
        
    - name: Upload coverage badge and report
      uses: actions/upload-artifact@v3
      with:
        name: coverage-report-${{ matrix.python-version }}
        path: |
          coverage-badge.svg
          coverage-report/
    
    - name: Check coverage thresholds
      run: |
        # Use pytest-cov's built-in coverage enforcement via .coveragerc
        # This will automatically enforce per-module thresholds

        # Extract and report current coverage 
        python -c "
        import xml.etree.ElementTree as ET
        import json
        
        # Print XML-based total coverage
        tree = ET.parse('coverage.xml')
        root = tree.getroot()
        coverage = float(root.attrib['line-rate']) * 100
        print(f'Total XML-reported coverage: {coverage:.2f}%')
        
        # Load JSON report for detailed coverage
        with open('coverage.json') as f:
            cov_data = json.load(f)
            
        # Get config from .coveragerc
        import configparser
        config = configparser.ConfigParser()
        config.read('.coveragerc')
        min_total = float(config['coverage:report']['fail_under'])
        
        # Report per-module coverage
        print('\\nPer-module coverage:')
        for file_path, metrics in cov_data['files'].items():
            if '/tests/' not in file_path:  # Skip test files
                cov_percent = metrics['summary']['percent_covered']
                print(f'{file_path}: {cov_percent:.2f}%')
        
        # Check if total coverage meets minimum threshold
        if coverage < min_total:
            print(f'\\nCoverage {coverage:.2f}% is below the minimum threshold of {min_total}%')
            exit(1)
        else:
            print(f'\\nCoverage {coverage:.2f}% meets the minimum threshold of {min_total}%')
        "

  ui-tests:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-qt pytest-html
    
    - name: Set up virtual display
      run: |
        sudo apt-get update
        sudo apt-get install -y xvfb libxkbcommon-x11-0 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-randr0 libxcb-render-util0 libxcb-xinerama0 libxcb-xkb1 libxkbcommon-x11-0
        export DISPLAY=:99.0
        Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &
        sleep 3
    
    - name: Run UI tests
      run: |
        python -m pytest -m ui --html=ui-test-report.html --self-contained-html
      env:
        DISPLAY: :99.0
    
    - name: Upload UI test reports
      uses: actions/upload-artifact@v3
      if: always()  # Upload even if tests fail
      with:
        name: ui-test-reports
        path: ui-test-report.html

  publish-report:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: [test, ui-tests]
    if: always()  # Run even if previous jobs fail
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Download all test reports
      uses: actions/download-artifact@v3
      
    - name: Create index.html for test reports
      run: |
        cat > index.html << EOF
        <!DOCTYPE html>
        <html>
        <head>
          <title>Imagen Desktop Test Reports</title>
          <style>
            body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
            h1 { color: #333; }
            .report-section { margin-bottom: 30px; }
            ul { list-style-type: none; padding-left: 20px; }
            li { margin-bottom: 10px; }
            a { color: #0366d6; text-decoration: none; }
            a:hover { text-decoration: underline; }
            .badge-container { margin: 20px 0; }
          </style>
        </head>
        <body>
          <h1>Imagen Desktop Test Reports</h1>
          
          <div class="badge-container">
            <h2>Code Coverage</h2>
            <img src="coverage-report-3.10/coverage-badge.svg" alt="Coverage Badge" />
          </div>
          
          <div class="report-section">
            <h2>Unit Tests Reports</h2>
            <ul>
        EOF
        
        # Add links to Python version test reports
        for ver in 3.9 3.10 3.11; do
          if [ -f "test-reports-$ver/pytest-report.html" ]; then
            echo "      <li><a href=\"test-reports-$ver/pytest-report.html\">Python $ver Test Report</a></li>" >> index.html
          fi
        done
        
        # Add coverage reports
        if [ -d "test-reports-3.10/htmlcov" ]; then
          echo "      <li><a href=\"test-reports-3.10/htmlcov/index.html\">Coverage HTML Report</a></li>" >> index.html
        fi
        
        if [ -f "coverage-report-3.10/coverage.md" ]; then
          # Convert markdown to HTML and include in the page
          echo "      <li><a href=\"coverage-report-3.10/coverage.md\">Coverage Markdown Report</a></li>" >> index.html
        fi
        
        # Add UI test report link
        cat >> index.html << EOF
            </ul>
          </div>
          
          <div class="report-section">
            <h2>UI Tests Report</h2>
            <ul>
              <li><a href="ui-test-reports/ui-test-report.html">UI Tests Report</a></li>
            </ul>
          </div>
          
          <div class="report-section">
            <h2>Latest Build Information</h2>
            <ul>
              <li>Build Date: $(date)</li>
              <li>Commit: ${{ github.sha }}</li>
              <li><a href="https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}">View GitHub Actions Run</a></li>
            </ul>
          </div>
        </body>
        </html>
        EOF
    
    - name: Setup Pages
      uses: actions/configure-pages@v3
    
    - name: Upload artifact
      uses: actions/upload-pages-artifact@v1
      with:
        path: '.'
        
    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v2
      if: github.ref == 'refs/heads/master'  # Only deploy on master branch